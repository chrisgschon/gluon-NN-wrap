{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\tests\\old\\test_attrs_data.py:251: DeprecationWarning: invalid escape sequence \\H\n",
      "  s = b\"Hello\\x00\\Hello\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('train_data_features_sample.csv', index_col = 0)\n",
    "\n",
    "y = pd.read_csv('train_data_output_sample.csv', index_col = 0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_test, Y_tr, Y_test = train_test_split(X, y, test_size = 0.2, random_state = 5)\n",
    "\n",
    "from gluon_search import *\n",
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd, gluon\n",
    "\n",
    "mx_X_tr = mx.gluon.data.DataLoader(gluon.data.ArrayDataset(np.array(X_tr), np.array(Y_tr).astype(int)), batch_size = 64, shuffle = True)\n",
    "mx_X_test = mx.gluon.data.DataLoader(gluon.data.ArrayDataset(np.array(X_test), np.array(Y_test).astype(int)), batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_arr = np.array([[5,5], [10]])\n",
    "activations_arr = np.array([['relu', 'relu'], ['tanh']])\n",
    "loss_func = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1106"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = X_tr.shape[1]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "\n",
      "Building model with hidden layers : [5, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numexpr\\cpuinfo.py:109: DeprecationWarning: invalid escape sequence \\d\n",
      "  nbits = re.compile('(\\d+)bit').search(abits).group(1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numexpr\\cpuinfo.py:662: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\\s+stepping\\s+(?P<STP>\\d+)\", re.IGNORECASE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10  Train acc: 0.765  Test acc: 0.764\n",
      "-----------------------------------------------\n",
      "\n",
      "Building model with hidden layers : [10]\n",
      "Epoch 10  Train acc: 0.765  Test acc: 0.764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   epoch  model_id  test_accuracy  test_losses      time  train_accuracy  \\\n",
       " 0      1  241596.0       0.763831     0.546576  1.511556        0.762390   \n",
       " 1      2  241596.0       0.763831     0.546645  1.668435        0.764647   \n",
       " 2      3  241596.0       0.763831     0.547024  1.475424        0.764647   \n",
       " 3      4  241596.0       0.763831     0.546679  1.496518        0.764647   \n",
       " 4      5  241596.0       0.763831     0.546923  1.491966        0.764647   \n",
       " 5      6  241596.0       0.763831     0.546688  1.604768        0.764647   \n",
       " 6      7  241596.0       0.763831     0.546720  1.533075        0.764647   \n",
       " 7      8  241596.0       0.763831     0.546720  1.444340        0.764647   \n",
       " 8      9  241596.0       0.763831     0.546743  1.496479        0.764647   \n",
       " 9     10  241596.0       0.763831     0.546678  1.490462        0.764647   \n",
       " 0      1   15122.0       0.763831     0.547647  1.364126        0.761972   \n",
       " 1      2   15122.0       0.763831     0.548043  1.400223        0.764647   \n",
       " 2      3   15122.0       0.763831     0.546679  1.574186        0.764647   \n",
       " 3      4   15122.0       0.763831     0.549634  1.282911        0.764647   \n",
       " 4      5   15122.0       0.763831     0.550314  1.284916        0.764647   \n",
       " 5      6   15122.0       0.763831     0.550077  1.330037        0.764647   \n",
       " 6      7   15122.0       0.763831     0.549549  1.280405        0.764647   \n",
       " 7      8   15122.0       0.763831     0.554261  1.285418        0.764647   \n",
       " 8      9   15122.0       0.763831     0.554568  1.302463        0.764647   \n",
       " 9     10   15122.0       0.763831     0.557206  1.313492        0.764647   \n",
       " \n",
       "    train_losses  \n",
       " 0      0.559907  \n",
       " 1      0.545715  \n",
       " 2      0.545812  \n",
       " 3      0.545749  \n",
       " 4      0.545723  \n",
       " 5      0.545621  \n",
       " 6      0.545697  \n",
       " 7      0.545675  \n",
       " 8      0.545682  \n",
       " 9      0.545688  \n",
       " 0      0.552401  \n",
       " 1      0.548996  \n",
       " 2      0.547452  \n",
       " 3      0.548171  \n",
       " 4      0.548806  \n",
       " 5      0.550547  \n",
       " 6      0.552342  \n",
       " 7      0.552169  \n",
       " 8      0.554934  \n",
       " 9      0.557207  , Sequential(\n",
       "   (0): Dense(1106 -> 10, Activation(tanh))\n",
       "   (1): Dropout(p = 0.1)\n",
       "   (2): Dense(10 -> 2, Activation(relu))\n",
       " ))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_over_NNs(X_tr, X_test, Y_tr, Y_test, epochs = epochs, num_hidden_arr = num_hidden_arr, activations_arr = activations_arr, loss_func = loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
