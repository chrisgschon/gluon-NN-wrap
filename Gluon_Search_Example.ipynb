{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple example of how to explore different architectures. The data is a 23k sample from the DrivenData PredictingPoverty competition, the features have been engineered already from survey data and the output is a true/false for weather the respondent is poor or not. \n",
    "\n",
    "The neural networks both converge fast to their best configuration, so the example isn't very interesting from a architectural challenge, but is more to demonstrate how to to use the gluon_search script to summarise training experiments for different feed-forward neural nets in an automated way. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('train_data.csv', index_col = 0)\n",
    "\n",
    "y = pd.read_csv('train_output.csv', index_col = 0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_test, Y_tr, Y_test = train_test_split(X, y, test_size = 0.2, random_state = 5)\n",
    "\n",
    "from gluon_search import *\n",
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd, gluon\n",
    "\n",
    "mx_X_tr = mx.gluon.data.DataLoader(gluon.data.ArrayDataset(np.array(X_tr), np.array(Y_tr).astype(int)), batch_size = 64, shuffle = True)\n",
    "mx_X_test = mx.gluon.data.DataLoader(gluon.data.ArrayDataset(np.array(X_test), np.array(Y_test).astype(int)), batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_arr = np.array([[20,20], [10,10,10]])\n",
    "activations_arr = np.array([['relu', 'relu'], ['tanh', 'tanh', 'tanh']])\n",
    "loss_func = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19384</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991304</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.278301</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.996296</td>\n",
       "      <td>0.003425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27117</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.986957</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048571</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.270533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.004668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.382609</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.775867</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.474074</td>\n",
       "      <td>0.018507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13229</th>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.875604</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995652</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365717</td>\n",
       "      <td>0.003412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26729</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.870773</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.640497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4    5         6  \\\n",
       "19384  0.071429  0.011111  0.000000  0.777778  1.000000  1.0  0.991304   \n",
       "27117  0.071429  0.022222  0.166667  0.611111  1.000000  0.8  0.986957   \n",
       "5249   0.000000  0.788889  0.083333  0.833333  0.923913  1.0  0.382609   \n",
       "13229  0.214286  0.000000  0.000000  0.888889  0.875604  1.0  0.995652   \n",
       "26729  0.071429  0.005556  0.166667  0.777778  0.870773  1.0  0.982609   \n",
       "\n",
       "              7         8    9        10        11        12        13   14  \\\n",
       "19384  0.869565  0.000000  0.0  0.022857  0.333333  0.278301  0.000079  1.0   \n",
       "27117  0.913043  0.166667  0.0  0.048571  0.333333  0.270533  0.000000  1.0   \n",
       "5249   1.000000  0.083333  0.0  0.405714  0.333333  0.775867  0.000300  1.0   \n",
       "13229  0.826087  0.000000  0.0  0.008571  0.000000  0.365717  0.003412  1.0   \n",
       "26729  0.739130  0.166667  0.0  0.242857  0.333333  0.640497  0.000000  0.5   \n",
       "\n",
       "             15        16    17        18        19  \n",
       "19384  0.166667  0.857143  0.75  0.996296  0.003425  \n",
       "27117  0.166667  1.000000  1.00  0.988889  0.004668  \n",
       "5249   0.333333  1.000000  1.00  0.474074  0.018507  \n",
       "13229  0.333333  0.857143  1.00  1.000000  0.013921  \n",
       "26729  0.166667  0.714286  0.75  1.000000  0.003472  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19384</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27117</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13229</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26729</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        poor\n",
       "19384  False\n",
       "27117  False\n",
       "5249   False\n",
       "13229   True\n",
       "26729  False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0msearch_over_NNs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_hidden_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivations_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_std\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Function for searching over Gluon NN architectures and hyperparameters. \n",
       "X_tr: original training data, numpy array\n",
       "X_test: original test data, numpy array\n",
       "Y_tr: numpy array of training labels\n",
       "Y_test: numpy array of test labels\n",
       "epochs: number of iterations over training data\n",
       "num_hidden_arr: array of num_hidden lists, providing the different architectures\n",
       "acitvations_arr: array of activations lists, giving the activation functions of the layers\n",
       "loss_func: a loss function from Gluon loss API \n",
       "init_std: standard deviation of weight initialisation (fixed to be normal mean 0)\n",
       "learning_rate: the learning rate!\n",
       "momentum: the momentum!\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\chrisschon\\documents\\ml lab\\automation\\gluon_search.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?search_over_NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "\n",
      "Building model with hidden layers : [20, 20]\n",
      "-----------------------------------------------\n",
      "\n",
      "Building model with hidden layers : [10, 10, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   epoch  model_id  test_accuracy  test_losses      time  train_accuracy  \\\n",
       " 0      1  876532.0       0.410162     0.694036  1.050168        0.401630   \n",
       " 1      2  876532.0       0.684272     0.693271  0.983589        0.518303   \n",
       " 2      3  876532.0       0.743607     0.693169  1.006583        0.611701   \n",
       " 3      4  876532.0       0.758482     0.693150  1.029741        0.651400   \n",
       " 4      5  876532.0       0.761992     0.693148  0.999394        0.673214   \n",
       " 0      1  655631.0       0.748955     0.692904  1.113874        0.632177   \n",
       " 1      2  655631.0       0.763831     0.690865  1.135223        0.742165   \n",
       " 2      3  655631.0       0.763831     0.687962  1.100153        0.764689   \n",
       " 3      4  655631.0       0.763831     0.685134  1.082881        0.764647   \n",
       " 4      5  655631.0       0.763831     0.682310  1.081841        0.764647   \n",
       " \n",
       "    train_losses  \n",
       " 0      0.695812  \n",
       " 1      0.694529  \n",
       " 2      0.693946  \n",
       " 3      0.693713  \n",
       " 4      0.693607  \n",
       " 0      0.693189  \n",
       " 1      0.692059  \n",
       " 2      0.689510  \n",
       " 3      0.686609  \n",
       " 4      0.683749  , Sequential(\n",
       "   (0): Dense(20 -> 10, Activation(tanh))\n",
       "   (1): Dropout(p = 0.1)\n",
       "   (2): Dense(10 -> 10, Activation(tanh))\n",
       "   (3): Dropout(p = 0.1)\n",
       "   (4): Dense(10 -> 10, Activation(tanh))\n",
       "   (5): Dropout(p = 0.1)\n",
       "   (6): Dense(10 -> 2, Activation(relu))\n",
       " ))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_over_NNs(X_tr, X_test, Y_tr, Y_test, epochs = epochs, num_hidden_arr = num_hidden_arr, activations_arr = activations_arr, loss_func = loss_func, learning_rate = 0.00001, momentum = 0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
